{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc7ffba-248f-4a4b-bff0-31d12430d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "import joblib\n",
    "# https://www.analyticsvidhya.com/blog/2023/02/how-to-save-and-load-machine-learning-models-in-python-using-joblib-library/\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import shap\n",
    "# https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\n",
    "from PIL import Image, ImageTk\n",
    "import io\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2465d-7174-4e17-b7d1-9d7381e56d7b",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17a267f-33e4-4377-ae38-1dff424e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"stacking_model.pkl\")\n",
    "expected_features = joblib.load(\"expected_feature.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd21e59c-fadb-4a45-a380-82a258eb08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    state_mapping = {\n",
    "        'AK': 'Alaska', 'AL': 'Alabama', 'AR': 'Arkansas', 'AZ': 'Arizona', 'CA': 'California',\n",
    "        'CO': 'Colorado', 'CT': 'Connecticut', 'DC': 'District of Columbia', 'DE': 'Delaware',\n",
    "        'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'IA': 'Iowa', 'ID': 'Idaho',\n",
    "        'IL': 'Illinois', 'IN': 'Indiana', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts', 'MD': 'Maryland', 'ME': 'Maine', 'MI': 'Michigan', 'MN': 'Minnesota',\n",
    "        'MO': 'Missouri', 'MS': 'Mississippi', 'MT': 'Montana', 'NC': 'North Carolina', 'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NV': 'Nevada',\n",
    "        'NY': 'New York', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania',\n",
    "        'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee',\n",
    "        'TX': 'Texas', 'UT': 'Utah', 'VA': 'Virginia', 'VT': 'Vermont', 'WA': 'Washington',\n",
    "        'WI': 'Wisconsin', 'WV': 'West Virginia', 'WY': 'Wyoming'\n",
    "    }\n",
    "    \n",
    "    region_mapping = {\n",
    "        'Alaska': 'West', 'Alabama': 'SouthEast', 'Arkansas': 'SouthEast', 'Arizona': 'SouthWest',\n",
    "        'California': 'West', 'Colorado': 'West', 'Connecticut': 'NorthEast',\n",
    "        'District of Columbia': 'SouthEast', 'Delaware': 'SouthEast', 'Florida': 'SouthEast',\n",
    "        'Georgia': 'SouthEast', 'Hawaii': 'West', 'Iowa': 'MidWest', 'Idaho': 'West',\n",
    "        'Illinois': 'MidWest', 'Indiana': 'MidWest', 'Kansas': 'MidWest', 'Kentucky': 'SouthEast',\n",
    "        'Louisiana': 'SouthEast', 'Massachusetts': 'NorthEast', 'Maryland': 'NorthEast',\n",
    "        'Maine': 'NorthEast', 'Michigan': 'MidWest', 'Minnesota': 'MidWest', 'Missouri': 'MidWest',\n",
    "        'Mississippi': 'SouthEast', 'Montana': 'West', 'North Carolina': 'SouthEast',\n",
    "        'North Dakota': 'MidWest', 'Nebraska': 'MidWest', 'New Hampshire': 'NorthEast',\n",
    "        'New Jersey': 'NorthEast', 'New Mexico': 'SouthWest', 'Nevada': 'West', 'New York': 'NorthEast',\n",
    "        'Ohio': 'MidWest', 'Oklahoma': 'SouthWest', 'Oregon': 'West', 'Pennsylvania': 'NorthEast',\n",
    "        'Rhode Island': 'NorthEast', 'South Carolina': 'SouthEast', 'South Dakota': 'MidWest',\n",
    "        'Tennessee': 'SouthEast', 'Texas': 'SouthWest', 'Utah': 'West', 'Virginia': 'SouthEast',\n",
    "        'Vermont': 'NorthEast', 'Washington': 'West', 'Wisconsin': 'MidWest', 'West Virginia': 'SouthEast',\n",
    "        'Wyoming': 'West'\n",
    "    }\n",
    "    \n",
    "    # mapping state code to the state name then to region\n",
    "    data['addr_state'] = data['addr_state'].map(state_mapping)\n",
    "    data['region'] = data['addr_state'].map(region_mapping)\n",
    "\n",
    "    data.drop(columns= 'addr_state', inplace=True)\n",
    "\n",
    "    data['term'] = data['term'].map({' 36 months': 36, ' 60 months': 60})\n",
    "\n",
    "    # sample data - with features similar to the features used in model deevelopment stage\n",
    "    data = data[['mock_id','loan_amnt', 'term', 'int_rate', 'installment', 'home_ownership', \n",
    "    'annual_inc', 'verification_status', 'purpose', 'dti', 'delinq_2yrs', \n",
    "    'fico_range_low', 'inq_last_6mths', 'mths_since_last_delinq', 'open_acc', \n",
    "    'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', \n",
    "    'application_type', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', \n",
    "    'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', \n",
    "    'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', \n",
    "    'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'mo_sin_old_il_acct', \n",
    "    'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', \n",
    "    'mort_acc', 'mths_since_recent_bc', 'num_actv_bc_tl', 'num_actv_rev_tl', \n",
    "    'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', \n",
    "    'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', \n",
    "    'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'region', 'target']]\n",
    "\n",
    "    def divide(var_1, var_2):\n",
    "        return np.where(var_2 == 0, 0, var_1 / var_2)\n",
    "\n",
    "    data['annual_inc_installment'] = divide(data['annual_inc'], data['installment'])\n",
    "    data['revol_bal_annual_inc'] = divide(data['revol_bal'], data['annual_inc'])\n",
    "    data['annual_inc_dti'] = data['annual_inc'] * data['dti']\n",
    "    data['loan_amnt_dti'] = data['loan_amnt'] * data['dti']\n",
    "\n",
    "    bins = [0, 20000, 50000, 100000, 200000, np.inf]\n",
    "    labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "    data['annual_inc_binned'] = pd.cut(data['annual_inc'], bins=bins, labels=labels)\n",
    "    data['revol_bal_binned'] = pd.cut(data['revol_bal'], bins=bins, labels=labels)\n",
    "\n",
    "    # handle missing values if any\n",
    "    data['annual_inc_binned'] = data['annual_inc_binned'].cat.add_categories('none')\n",
    "    data['revol_bal_binned'] = data['revol_bal_binned'].cat.add_categories('none')\n",
    "    \n",
    "    data['annual_inc_binned'].fillna('none', inplace=True)\n",
    "    data['revol_bal_binned'].fillna('none', inplace=True)\n",
    "\n",
    "    data.drop(columns= ['installment'], inplace=True)\n",
    "\n",
    "    # one-hot encoding \n",
    "    columns_to_check = data.select_dtypes(exclude='number').columns.tolist()\n",
    "    features_to_encode = columns_to_check\n",
    "\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    encoded_features = encoder.fit_transform(data[features_to_encode])\n",
    "    encoded_data = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(features_to_encode))\n",
    "\n",
    "    data = data.drop(features_to_encode, axis=1)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    encoded_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "    mock_id = data['mock_id']\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data[expected_features]), columns=expected_features)\n",
    "\n",
    "    return data.fillna(0), mock_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f5b081-d364-4027-9c54-b896f6464ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    if file_path:\n",
    "        try:\n",
    "            result_text.delete(1.0, tk.END)\n",
    "            uploaded_data = pd.read_csv(file_path)\n",
    "\n",
    "            # data preparation\n",
    "            data, mock_id = cleaning(uploaded_data)\n",
    "            predictions = model.predict(data)\n",
    "            results = pd.DataFrame({'mock_id': mock_id, 'prediction': predictions})\n",
    "\n",
    "            # add the status column\n",
    "            results['status'] = results['prediction'].map({0: 'Non-Default', 1: 'Default'})\n",
    "\n",
    "            result_text.insert(tk.END, \"Predictions:\\n\")\n",
    "            result_text.insert(tk.END, results.head(25).to_string(index=False))\n",
    "\n",
    "            data_sample = data.sample(20, random_state=42)\n",
    "\n",
    "            # SHAP analysis\n",
    "            xgboost_model = model.named_estimators_['XGBoost']\n",
    "            explainer_xgb = shap.TreeExplainer(xgboost_model)\n",
    "            shap_values_xgb = explainer_xgb.shap_values(data_sample)\n",
    "\n",
    "            # summary plot \n",
    "            summary_plot_path = \"shap_summary_plot.png\"\n",
    "            shap.summary_plot(shap_values_xgb, data_sample, show=False)\n",
    "            plt.savefig(summary_plot_path)\n",
    "            plt.close()\n",
    "            shap_plot(summary_plot_path, \"SHAP Summary Plot\")\n",
    "            \n",
    "            # show a simple decision tree (the one in the stacked model)\n",
    "            decision_tree(model.named_estimators_['Decision Tree'], list(data.columns))\n",
    "\n",
    "            # individual SHAP explanations\n",
    "            individual_shap_explanations(data_sample, shap_values_xgb, mock_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "def individual_shap_explanations(data_sample, shap_values, mock_id):\n",
    "    explainer_window = tk.Toplevel(root)\n",
    "    explainer_window.title(\"Individual SHAP Explanations\")\n",
    "\n",
    "    # Tkinter to display individual explanations\n",
    "    explainer_text = tk.Text(explainer_window, height=20, width=80)\n",
    "    explainer_text.pack(pady=20)\n",
    "\n",
    "    for i in range(len(data_sample)):\n",
    "        id = mock_id[i]\n",
    "        shap_val = shap_values[i]\n",
    "        explanation = f\"ID: {id}\\n\"\n",
    "        explanation += f\"Prediction: {model.predict(data_sample.iloc[[i]])[0]}\\n\"\n",
    "        explanation += f\"Status: {'Default' if model.predict(data_sample.iloc[[i]])[0] == 1 else 'Non-Default'}\\n\"\n",
    "        explanation += \"Feature Contributions:\\n\"\n",
    "        for feature, value in zip(data_sample.columns, shap_val):\n",
    "            explanation += f\"{feature}: {value:.4f}\\n\"\n",
    "        explanation += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "        explainer_text.insert(tk.END, explanation)\n",
    "\n",
    "def shap_plot(plot_path, title):\n",
    "    plot_window = tk.Toplevel(root)\n",
    "    plot_window.title(title)\n",
    "\n",
    "    # open and display the plots\n",
    "    img = Image.open(plot_path)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    img_label = tk.Label(plot_window, image=img)\n",
    "    img_label.image = img  \n",
    "    img_label.pack()\n",
    "\n",
    "def decision_tree(tree_model, feature_names):\n",
    "    plot_window = tk.Toplevel()\n",
    "    plot_window.title(\"Decision Tree\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    plot_tree(tree_model, feature_names=feature_names, class_names=['Non-Default', 'Default'],\n",
    "        filled=True, rounded=True, proportion=True, ax=ax\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # display plots as images\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    img_label = tk.Label(plot_window, image=img)\n",
    "    img_label.image = img  \n",
    "    img_label.pack()\n",
    "\n",
    "    buf.close()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b495b85f-869c-491f-86c5-b258ccfb0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising Tkinter root to run the GUI Application\n",
    "root = tk.Tk()\n",
    "root.title(\"Loan Prediction and Analysis\")\n",
    "\n",
    "info_label = tk.Label(root, text=(\n",
    "    \"Welcome to the Loan Prediction UI!\\n\\n\"\n",
    "    \"Kindly have your data ready in a CSV file and upload it using the 'Upload CSV' button.\\n\\n\"\n",
    "    \"The results you will receive include:\\n\"\n",
    "    \"- User ID\\n\"\n",
    "    \"- Predictions on whether the borrower would default or not\\n\"\n",
    "    \"- Status Non-Default or Default\\n\"\n",
    "    \"- SHAP values to understand why a default might occur\\n\"\n",
    "    \"- A decision tree to visualise the decision-making process\\n\\n\"\n",
    "    \"Press 'Upload CSV' to get started.\"\n",
    "), wraplength=400, justify=\"left\")\n",
    "info_label.pack(pady=20)\n",
    "\n",
    "# buttons to uploading the data\n",
    "upload_button = tk.Button(root, text=\"Upload CSV\", command=upload_file)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# displaying the result\n",
    "result_text = tk.Text(root, height=10, width=80)\n",
    "result_text.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc797a7-5fe9-4b7d-9bdc-08d6ad4010bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
